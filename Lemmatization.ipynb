{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqCilyYOhaHh"
   },
   "source": [
    "# Lemmatiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{10}} {token.pos_:{8}} {token.lemma:<{25}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I          PRON     4690420944186131903       I\n",
      "went       VERB     8004577259940138793       go\n",
      "there      ADV      2112642640949226496       there\n",
      "to         PART     3791531372978436496       to\n",
      "give       VERB     11640825575873464194      give\n",
      "my         PRON     227504873216781231        my\n",
      "job        NOUN     18425606103329785088      job\n",
      "interview  NOUN     14070363061372230176      interview\n",
      ".          PUNCT    12646065887601541794      .\n",
      "i          PRON     4690420944186131903       I\n",
      "was        AUX      10382539506755952630      be\n",
      "so         ADV      9781598966686434415       so\n",
      "nervous    ADJ      11216294436333666104      nervous\n",
      "and        CCONJ    2283656566040971221       and\n",
      "anxiously  ADV      13229654190760318445      anxiously\n",
      "waiting    VERB     6203382976377178934       wait\n",
      "for        ADP      16037325823156266367      for\n",
      "my         PRON     227504873216781231        my\n",
      "turn       NOUN     7124218691546400199       turn\n",
      "working    VERB     10038440415813069799      work\n",
      "!          PUNCT    17494803046312582752      !\n",
      "anxiousness NOUN     2555402799789132501       anxiousness\n"
     ]
    }
   ],
   "source": [
    "var2 = nlp(u\"I went there to give my job interview. i was so nervous and anxiously waiting for my turn working! anxiousness\")\n",
    "show_lemmas(var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous   ADJ      12333698124728187681      generous\n",
      "generation NOUN     12757012465390741750      generation\n",
      "generously ADV      1539093411080084076       generously\n",
      "generate   VERB     17214151181767158707      generate\n",
      "generated  VERB     17214151181767158707      generate\n",
      "rigorously ADV      1070276518329908818       rigorously\n",
      "rigging    VERB     13592696562782938413      rig\n"
     ]
    }
   ],
   "source": [
    "var4 = nlp(u\"generous generation generously generate generated rigorously rigging\")\n",
    "show_lemmas(var4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have       AUX      14692702688101715474      have\n",
      "u          NOUN     12247454108283186160      u\n",
      "waited     VERB     6203382976377178934       wait\n",
      "for        ADP      16037325823156266367      for\n",
      "too        ADV      12286903790479710773      too\n",
      "long       ADJ      12965068231793614765      long\n",
      "for        ADP      16037325823156266367      for\n",
      "getting    VERB     2013399242189103424       get\n",
      "the        DET      7425985699627899538       the\n",
      "bill       NOUN     8021635565988888124       bill\n",
      "paid       VERB     645224182615914541        pay\n",
      ".          PUNCT    12646065887601541794      .\n",
      "i          PRON     4690420944186131903       I\n",
      "am         AUX      10382539506755952630      be\n",
      "also       ADV      12084876542534825196      also\n",
      "finishing  VERB     15571920043411331145      finish\n",
      "my         PRON     227504873216781231        my\n",
      "task       NOUN     1048061966900118739       task\n"
     ]
    }
   ],
   "source": [
    "var4 = nlp(u\"have u waited for too long for getting the bill paid. i am also finishing my task\")\n",
    "show_lemmas(var4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generously\n",
      "work\n",
      "and\n",
      "they\n",
      "be\n",
      "make\n",
      "repeatedly\n",
      "neumorous\n",
      "play\n",
      "well\n"
     ]
    }
   ],
   "source": [
    "x=nlp('Generously working and they are making repeatedly neumorous plays better')\n",
    "for i in x:\n",
    "    print(i.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jolly\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "x=nlp('jolly was')\n",
    "for i in x:\n",
    "    print(i.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5v33WyRCR2S"
   },
   "source": [
    "# Stop Words\n",
    "Stop words are those words that do not contribute to the deeper meaning of the phrase. They are the most common words such as: the, a, and is. For some applications like documentation classification, it may make sense to remove stop words. NLTK provides a list of commonly agreed upon stop words for a variety of languages, such as English.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1ehwqoXCR2T"
   },
   "outputs": [],
   "source": [
    "# Perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "O3drpJkBCR2Z",
    "outputId": "164d75d1-7e89-4b18-f9b5-f607d7abc6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do', 'might', 'herself', 'my', 'the', 'done', 'mine', \"n't\", 'every', 'out', 'again', 'at', 'it', 'its', 'one', 'does', 'third', 'beforehand', 'empty', 'are', 'made', 'above', 'thereupon', 'through', 'often', 'them', 'six', 'hereupon', 'somehow', 'get', 'anywhere', 'can', 'show', 'full', 'nowhere', 'in', 'along', 'or', 'everything', 'since', 'ours', 'thru', 'first', 'keep', 'put', 'themselves', 'before', 'must', 'really', 'same', 'because', 'here', 'otherwise', 'within', '‘ve', 're', 'none', 'against', 'except', '‘m', 'however', 'who', 'other', 'also', '’ve', 'nine', 'anything', 'between', 'thus', 'so', 'n‘t', 'over', '’re', 'under', 'her', 'were', 'will', 'namely', 'next', 'due', 'could', 'seems', 'four', 'his', 'had', 'besides', 'until', \"'re\", 'enough', 'as', 'hence', 'move', 'becomes', 'fifty', 'last', \"'s\", 'after', 'itself', 'whither', 'meanwhile', 'ourselves', 'whole', 'ten', 'behind', 'see', 'than', 'with', 'our', 'about', 'doing', 'which', 'anyway', 'eight', 'toward', 'less', \"'ve\", 'almost', 'something', \"'m\", 'never', 'if', 'these', 'been', 'least', 'beside', 'thence', 'three', 'onto', 'used', 'himself', 'regarding', 'both', 'twenty', 'she', 'others', 'whose', 'hereby', 'most', 'own', 'him', 'when', \"'ll\", 'during', 'i', 'was', 'sometimes', 'everyone', 'yourselves', 'of', '‘ll', 'ca', 'am', 'yourself', 'why', 'to', 'what', 'he', 'somewhere', 'being', 'via', 'be', 'though', 'that', 'please', 'not', 'whatever', 'unless', 'your', 'whereby', 'even', 'there', 'such', 'those', 'seem', '’ll', 'more', 'very', 'where', 'thereafter', 'anyone', 'mostly', 'this', 'anyhow', '’d', 'seeming', 'say', 'among', 'off', 'eleven', 'side', 'yours', 'whereafter', 'by', 'already', 'an', 'throughout', 'using', 'latter', 'nobody', '’s', 'whether', 'their', 'then', 'we', 'give', 'wherein', 'take', 'herein', 'became', 'and', 'many', 'someone', 'just', 'make', 'nothing', 'without', 'various', 'now', 'much', 'noone', 'us', 'whereupon', 'hereafter', 'upon', 'rather', 'twelve', '‘re', 'always', 'down', 'either', 'but', 'should', 'is', 'on', 'another', 'some', 'together', 'while', 'around', 'although', 'nevertheless', 'quite', 'five', 'ever', 'perhaps', 'whom', 'once', 'all', 'have', 'becoming', 'per', 'several', 'two', 'each', 'did', 'neither', 'call', 'else', 'back', 'few', 'from', 'below', 'further', 'sixty', 'into', 'how', 'elsewhere', 'beyond', 'thereby', 'whereas', 'hundred', 'go', 'for', 'still', 'whenever', 'me', 'serious', 'forty', '’m', 'former', 'therein', 'fifteen', 'therefore', 'too', 'they', 'bottom', 'n’t', 'sometime', '‘d', 'front', 'you', \"'d\", 'moreover', 'towards', 'top', 'hers', 'has', 'indeed', '‘s', 'alone', 'amount', 'whence', 'no', 'part', 'nor', 'a', 'seemed', 'everywhere', 'up', 'any', 'only', 'amongst', 'would', 'whoever', 'afterwards', 'yet', 'name', 'well', 'myself', 'may', 'cannot', 'formerly', 'across', 'wherever', 'latterly', 'become'}\n"
     ]
    }
   ],
   "source": [
    "# Print the set of spaCy's default stop words (remember that sets are unordered):\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "diWTTaRICR2g",
    "outputId": "ec779a00-2e5b-43e9-b526-721cfa755ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWu19KsbCR2k"
   },
   "source": [
    "## To see if a word is a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Sxj_JjAdCR2k",
    "outputId": "2fbdde00-9d43-42d9-b438-83dbf1040055"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ep_V7bnOCR2o",
    "outputId": "aee5a5df-1185-4533-cda7-44dccdcddb8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1vIs64dCR2t"
   },
   "outputs": [],
   "source": [
    "# Add the word to the set of stop words. Use lowercase!\n",
    "nlp.Defaults.stop_words.add('mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SQnVv6JEiqHC"
   },
   "outputs": [],
   "source": [
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['mystery'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IO-WF_1mCR2x",
    "outputId": "5182d797-f8b1-47b4-c384-2d823b415699"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oMMCzOUACR21",
    "outputId": "8e8ae166-3a1f-46b9-b60c-d5a13f4deca4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p58rPB42CR24"
   },
   "source": [
    "## To remove a stop word\n",
    "Alternatively, you may decide that `'beyond'` should not be considered a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KEtYBNRCR25"
   },
   "outputs": [],
   "source": [
    "# Remove the word from the set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "\n",
    "# Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iQr5IK3CCR28",
    "outputId": "a4f3f68a-6268-4ed1-c262-f870b2bd369c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZLnWlnDQCR2_",
    "outputId": "019a669d-b077-4289-f567-5df00fbcb4d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['beyond'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TCyp1UmXCxgJ",
    "outputId": "3ea34f16-1f46-4b5a-b25e-d9d720a9debc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ammara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# load data\n",
    "text = 'The Quick brown fox jump over the lazy dog!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pehkONOeDPd-",
    "outputId": "f65a8bd5-7adf-4f49-b4e5-a191f4378f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog', '!']\n"
     ]
    }
   ],
   "source": [
    "# split into words\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K0zTYJKID--l",
    "outputId": "2aadf62e-6504-43d6-f9db-a62d16c59c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog', '!']\n"
     ]
    }
   ],
   "source": [
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PXAJpO5hEEcj",
    "outputId": "2f5afa33-d27f-4a47-8112-770cd7a2da8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile('[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]')\n"
     ]
    }
   ],
   "source": [
    "# prepare regex for char filtering\n",
    "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "print(re_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IRupmyA-EF7z",
    "outputId": "57187a4f-2fb1-4500-e194-227f377a05f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog', '']\n"
     ]
    }
   ],
   "source": [
    "# remove punctuation from each word\n",
    "stripped = [re_punc.sub('', w) for w in tokens]\n",
    "print(stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c0__AkhWEHPT",
    "outputId": "5d8bf427-19e9-47a0-c269-31d4ce85f49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jump', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6WYqyINsEIhD",
    "outputId": "1917537b-051f-43e8-bb76-6d741163eecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "# filter out non-stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2DdtvLMggo4P",
    "outputId": "e32cca62-64b8-4b6a-8479-330e2b485d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['dog'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['the'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "StopWords_FahadHussainCS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
